{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from keras.models import load_model\n",
    "from skimage import color\n",
    "\n",
    "from dataset.utils.inception_utils import inception_resnet_v2_predict\n",
    "from dataset.utils.resize import resize_pad_frame\n",
    "from dataset.utils.shared import frames_per_video, default_nn_input_width, default_nn_input_height, resnet_input_height, resnet_input_width, dir_test, dir_test_results\n",
    "from model import FusionLayer\n",
    "import seaborn as sns \n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "%matplotlib inline\n",
    "\n",
    "sns.set(rc={'figure.figsize':(20,12)})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utility functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_video(file):\n",
    "    '''\n",
    "    Parameters\n",
    "    ----------\n",
    "    file - path to video file \n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    frames - frames array of the video\n",
    "    '''\n",
    "    \n",
    "    video = cv2.VideoCapture(file)\n",
    "    frames = []\n",
    "    while video.isOpened():\n",
    "        ret, frame = video.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        frames.append(frame)\n",
    "    frames = np.asarray(frames)\n",
    "    return frames\n",
    "\n",
    "\n",
    "def get_lab_layer(frames):\n",
    "    '''\n",
    "        Parameters\n",
    "        -----------\n",
    "        frames - color/gray video frames with 3 chanels\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        (rgb2lab, gray2lab) - RGB frames converted to LAB, GRAY frames converted to LAB\n",
    "    '''\n",
    "    rgb2lab_frames = []\n",
    "    gray2lab_frames = []\n",
    "\n",
    "    for frame in frames:\n",
    "        resized_frame = resize_pad_frame(frame, (default_nn_input_height, default_nn_input_width), equal_padding=True)\n",
    "\n",
    "        rgb2lab_frame = color.rgb2lab(resized_frame)\n",
    "        rgb2lab_frames.append(rgb2lab_frame)\n",
    "        \n",
    "        rgb2gray_frame = color.rgb2gray(resized_frame)\n",
    "        \n",
    "#         Display Grayscale frame\n",
    "#         cv2.imshow('grey', rgb2gray_frame)\n",
    "#         cv2.waitKey(0)\n",
    "#         cv2.destroyAllWindows()\n",
    "        \n",
    "        gray2rgb_frame = color.gray2rgb(rgb2gray_frame)\n",
    "        lab_frame = color.rgb2lab(gray2rgb_frame)\n",
    "        gray2lab_frames.append(lab_frame)\n",
    "\n",
    "    return np.asarray(rgb2lab_frames), np.asarray(gray2lab_frames)\n",
    "\n",
    "\n",
    "def preprocess_frames(gray2lab_frames):\n",
    "    '''\n",
    "    Parameters\n",
    "    ---------\n",
    "    gray2lab_frames - LAB frames of Grayscale video\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    processed_l_layer - L Layer processed (L/50 - 1)\n",
    "    '''\n",
    "    processed = np.empty(gray2lab_frames.shape)\n",
    "    \n",
    "    processed[:, :, :, 0] = np.divide(gray2lab_frames[:, :, :, 0], 50) - 1  # data loss\n",
    "    processed[:, :, :, 1] = np.divide(gray2lab_frames[:, :, :, 1], 128)\n",
    "    processed[:, :, :, 2] = np.divide(gray2lab_frames[:, :, :, 2], 128)\n",
    "    \n",
    "    processed_l_layer = processed[:, :, :, np.newaxis, 0]\n",
    "    \n",
    "    return processed_l_layer\n",
    "\n",
    "\n",
    "def get_resnet_records(frames):\n",
    "    '''\n",
    "    Parameters\n",
    "    ----------\n",
    "    frames - original frames without color conversion or resizing\n",
    "    \n",
    "    Details\n",
    "    -------\n",
    "    Implementation adopted from Deep Kolorization implementation\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    predictions - restnet predictions \n",
    "    '''\n",
    "    resnet_input = []\n",
    "    for frame in frames:\n",
    "        resized_frame = resize_pad_frame(frame, (resnet_input_height, resnet_input_width))\n",
    "        gray_scale_frame = cv2.cvtColor(resized_frame, cv2.COLOR_RGB2GRAY)\n",
    "        gray_scale_frame_colored = cv2.cvtColor(gray_scale_frame, cv2.COLOR_GRAY2RGB)\n",
    "        resnet_input.append(gray_scale_frame_colored)\n",
    "    resnet_input = np.asarray(resnet_input)\n",
    "\n",
    "    predictions = inception_resnet_v2_predict(resnet_input)\n",
    "    return predictions\n",
    "\n",
    "\n",
    "def getInputRange(frames_count, time_steps, current_frame):\n",
    "    '''\n",
    "    Deciding the moving window\n",
    "    '''\n",
    "    # this function should change according to our selection of\n",
    "    frame_selection = []\n",
    "    last_selection = current_frame\n",
    "    for i in range(current_frame, current_frame - time_steps, -1):\n",
    "        if (i < 0):\n",
    "            frame_selection.append(last_selection)\n",
    "        else:\n",
    "            frame_selection.append(i)\n",
    "            last_selection = i\n",
    "    frame_selection = frame_selection[::-1]\n",
    "    return frame_selection\n",
    "\n",
    "\n",
    "def get_nn_input(l_layer, resnet_out):\n",
    "    '''\n",
    "    Define the flowchroma input\n",
    "    '''\n",
    "    frames_count = l_layer.shape[0]\n",
    "    time_steps = frames_per_video\n",
    "    X = []\n",
    "    Y = []\n",
    "\n",
    "    for i in range(frames_count):\n",
    "        frame_index_selection = getInputRange(frames_count, time_steps, i)\n",
    "        frame_selection = []\n",
    "        resnet_selection = []\n",
    "        for j in frame_index_selection:\n",
    "            frame_selection.append(l_layer[j])\n",
    "            resnet_selection.append(resnet_out[j])\n",
    "        X.append(frame_selection)\n",
    "        Y.append(resnet_selection)\n",
    "\n",
    "    X = np.asarray(X)\n",
    "    Y = np.asarray(Y)\n",
    "    return [X, Y]\n",
    "\n",
    "\n",
    "def post_process_predictions(original_l_layers, predicted_AB_layers):\n",
    "    '''\n",
    "    Combine original L layer and predicted AB Layers\n",
    "    '''\n",
    "    time_steps = frames_per_video\n",
    "    total_frames = original_l_layers.shape[0]\n",
    "    predicted_frames = []\n",
    "    for i in range(total_frames):\n",
    "        l_layer = original_l_layers[i]\n",
    "        a_layer = np.multiply(predicted_AB_layers[i, time_steps - 1, :, :, 0], 128) # select the first frame outof three predictions\n",
    "        b_layer = np.multiply(predicted_AB_layers[i, time_steps - 1, :, :, 1], 128)\n",
    "        frame = np.empty((240, 320, 3))\n",
    "        frame[:, :, 0] = l_layer\n",
    "        frame[:, :, 1] = a_layer\n",
    "        frame[:, :, 2] = b_layer\n",
    "        #frame = color.lab2rgb(frame)\n",
    "        predicted_frames.append(frame)\n",
    "    return np.asarray(predicted_frames)\n",
    "\n",
    "\n",
    "def save_output_video(frames, output_file):\n",
    "    '''\n",
    "    Save the output video\n",
    "    '''\n",
    "    fps = 20\n",
    "    size = (320, 240)\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
    "    out = cv2.VideoWriter(output_file, fourcc, fps, size)\n",
    "    count = 0\n",
    "    for frame in frames:\n",
    "        final_out = color.lab2rgb(frame)\n",
    "        #final_out = np.asarray(final_out).astype(int)\n",
    "        #plt.imshow(final_out)\n",
    "        final_out_write_video = final_out*255 # color.lab2rgb results values in [0,1]\n",
    "        final_out_write_video = final_out_write_video.astype(np.uint8)\n",
    "#         cv2.imshow('image', final_out)\n",
    "        count+=1\n",
    "#         cv2.waitKey(0)\n",
    "#         cv2.destroyAllWindows()\n",
    "        out.write(final_out_write_video)\n",
    "    out.release()\n",
    "\n",
    "    # write to output_file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running resnet model\n",
      "Combining L laber and resnet out\n"
     ]
    }
   ],
   "source": [
    "frames = get_video(dir_test+'/video_00002.avi')\n",
    "(rgb2lab_frames, gray2lab_frames) = get_lab_layer(frames)\n",
    "processed_l_layer = preprocess_frames(gray2lab_frames)\n",
    "print('running resnet model')\n",
    "predictions = get_resnet_records(frames)\n",
    "print('Combining L laber and resnet out')\n",
    "X = get_nn_input(processed_l_layer, predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading from checkpoint: checkpoints/flowchroma-epoch-00123-lr-0.0001-train_loss-0.0027-val_loss-0.0099.hdf5\n",
      "Flowchroma model predictions calculated\n"
     ]
    }
   ],
   "source": [
    "# run flowchroma model\n",
    "ckpts = glob.glob(\"checkpoints/*.hdf5\")\n",
    "latest_ckpt = max(ckpts, key=os.path.getctime)\n",
    "print(\"loading from checkpoint:\", latest_ckpt)\n",
    "model = load_model(latest_ckpt, custom_objects={'FusionLayer': FusionLayer})\n",
    "predictions = []\n",
    "for i in range(X[0].shape[0]):\n",
    "    predictions.append(model.predict([X[0][i:i+1],X[1][i:i+1]])[0])\n",
    "predictions = np.asarray(predictions)\n",
    "print(\"Flowchroma model predictions calculated\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Post-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame_predictions = post_process_predictions(gray2lab_frames[:,:,:,0], predictions)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_output_video(frame_predictions, dir_test_results+'/2.avi')\n",
    "# print(np.mean(frame_predictions[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ---------------------------------------------------------------------------------------------------\n",
    "# Other stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(rgb2lab_frames.shape)\n",
    "print(np.amax(rgb2lab_frames[0,:,:,0]))\n",
    "sns.heatmap(rgb2lab_frames[0,80:90,80:90,0],annot=True )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(gray2lab_frames.shape)\n",
    "print(np.amax(gray2lab_frames[0,:,:,0]))\n",
    "sns.heatmap(gray2lab_frames[0,80:90,80:90,0],annot=True )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(processed_l_layer.shape)\n",
    "print(np.amax(processed_l_layer[0,:,:,0]))\n",
    "sns.heatmap(processed_l_layer[0,80:90,80:90,0],annot=True )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# L Layer Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax,ax2) = plt.subplots(ncols=2)\n",
    "fig.subplots_adjust(wspace=0.01)\n",
    "\n",
    "sns.heatmap(frame_predictions[0,80:90,80:90,0],annot=True, ax=ax )\n",
    "sns.heatmap(rgb2lab_frames[0,80:90,80:90,0],annot=True, ax=ax2 )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A Layer Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax,ax2) = plt.subplots(ncols=2)\n",
    "fig.subplots_adjust(wspace=0.01)\n",
    "sns.heatmap(frame_predictions[1,80:90,80:90,1],annot=True, ax=ax )\n",
    "sns.heatmap(rgb2lab_frames[1,80:90,80:90,1],annot=True, ax=ax2 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# B Layer comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax,ax2) = plt.subplots(ncols=2)\n",
    "fig.subplots_adjust(wspace=0.01)\n",
    "sns.heatmap(frame_predictions[0,80:90,80:90,2],annot=True, ax=ax )\n",
    "sns.heatmap(rgb2lab_frames[0,80:90,80:90,2],annot=True, ax=ax2 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
